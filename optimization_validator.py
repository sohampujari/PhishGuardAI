#!/usr/bin/env python3
"""
PhishGuard AI - Comprehensive Optimization Validation
=====================================================

This script validates both performance and accuracy optimizations:
1. Tests the optimized detector against comprehensive test cases
2. Measures accuracy improvements
3. Validates SRS compliance
4. Generates final optimization report

Author: PhishGuard AI Team
Date: October 3, 2025
"""

import time
import json
import pandas as pd
from datetime import datetime
from optimized_detector import OptimizedPhishGuardDetector
from training.accuracy_optimizer import AccuracyTestSuite
import warnings
warnings.filterwarnings('ignore')

class OptimizationValidator:
    """Comprehensive validation of all optimizations."""
    
    def __init__(self):
        """Initialize validator."""
        self.optimized_detector = None
        
    def run_comprehensive_validation(self):
        """Run complete optimization validation."""
        
        print("ğŸ† PHISHGUARD AI - COMPREHENSIVE OPTIMIZATION VALIDATION")
        print("=" * 60)
        
        # Initialize optimized detector
        print("\n1ï¸âƒ£ Initializing Optimized System...")
        self.optimized_detector = OptimizedPhishGuardDetector(enable_caching=True)
        
        # Performance validation
        print("\n2ï¸âƒ£ Performance Validation...")
        perf_results = self._validate_performance()
        
        # Accuracy validation  
        print("\n3ï¸âƒ£ Accuracy Validation...")
        accuracy_results = self._validate_accuracy()
        
        # SRS compliance check
        print("\n4ï¸âƒ£ SRS Compliance Check...")
        compliance_results = self._check_srs_compliance(perf_results, accuracy_results)
        
        # Generate final report
        print("\n5ï¸âƒ£ Generating Final Report...")
        final_report = self._generate_final_report(perf_results, accuracy_results, compliance_results)
        
        return final_report
    
    def _validate_performance(self):
        """Validate performance optimizations."""
        
        print("âš¡ Testing Performance Optimizations...")
        
        # Create comprehensive test set
        test_cases = self._create_performance_test_set()
        
        # Test throughput
        start_time = time.time()
        results = self.optimized_detector.predict_batch_optimized(test_cases)
        total_time = time.time() - start_time
        
        throughput = (len(test_cases) / total_time) * 60 if total_time > 0 else 0
        
        # Test single prediction speed
        single_times = []
        for cse, suspicious in test_cases[:10]:
            start = time.time()
            self.optimized_detector.predict_single_optimized(cse, suspicious)
            single_times.append((time.time() - start) * 1000)
        
        performance_results = {
            'batch_throughput_per_minute': throughput,
            'single_prediction_avg_ms': sum(single_times) / len(single_times),
            'total_test_cases': len(test_cases),
            'processing_time_seconds': total_time,
            'cache_stats': self.optimized_detector.get_cache_stats(),
            'meets_srs_throughput': throughput >= 1000,
            'meets_srs_response_time': (sum(single_times) / len(single_times)) <= 500
        }
        
        print(f"   ğŸš€ Throughput: {throughput:.0f} domains/minute")
        print(f"   â±ï¸  Response time: {performance_results['single_prediction_avg_ms']:.1f}ms")
        print(f"   ğŸ’¾ Cache hits: {performance_results['cache_stats']['prediction_cache_size']}")
        
        return performance_results
    
    def _validate_accuracy(self):
        """Validate accuracy optimizations."""
        
        print("ğŸ¯ Testing Accuracy Optimizations...")
        
        # Create accuracy test suite
        test_suite = AccuracyTestSuite(self.optimized_detector)
        test_cases = test_suite.create_accuracy_test_data()
        
        # Run accuracy validation
        metrics, detailed_results = test_suite.run_accuracy_validation(
            self.optimized_detector, test_cases
        )
        
        accuracy_results = {
            'metrics': metrics,
            'detailed_results': detailed_results,
            'meets_srs_accuracy': metrics['accuracy'] >= 0.85,
            'meets_srs_recall': metrics['recall'] >= 0.90
        }
        
        print(f"   ğŸ“Š Overall Accuracy: {metrics['accuracy']:.1%}")
        print(f"   ğŸ” Threat Detection Recall: {metrics['recall']:.1%}")
        print(f"   ğŸ¯ F1-Score: {metrics['f1_score']:.1%}")
        
        return accuracy_results
    
    def _check_srs_compliance(self, perf_results, accuracy_results):
        """Check complete SRS compliance."""
        
        print("ğŸ“‹ Checking SRS Compliance...")
        
        srs_requirements = {
            'throughput_1000_plus': {
                'current': perf_results['batch_throughput_per_minute'],
                'target': 1000,
                'met': perf_results['meets_srs_throughput']
            },
            'response_time_500ms': {
                'current': perf_results['single_prediction_avg_ms'],
                'target': 500,
                'met': perf_results['meets_srs_response_time']
            },
            'accuracy_85_percent': {
                'current': accuracy_results['metrics']['accuracy'],
                'target': 0.85,
                'met': accuracy_results['meets_srs_accuracy']
            },
            'phishing_recall_90_percent': {
                'current': accuracy_results['metrics']['recall'],
                'target': 0.90,
                'met': accuracy_results['meets_srs_recall']
            }
        }
        
        total_requirements = len(srs_requirements)
        met_requirements = sum(1 for req in srs_requirements.values() if req['met'])
        compliance_percentage = (met_requirements / total_requirements) * 100
        
        compliance_results = {
            'requirements': srs_requirements,
            'total_requirements': total_requirements,
            'met_requirements': met_requirements,
            'compliance_percentage': compliance_percentage,
            'fully_compliant': compliance_percentage == 100
        }
        
        print(f"   ğŸ“Š SRS Compliance: {compliance_percentage:.1f}% ({met_requirements}/{total_requirements})")
        
        for req_name, req_data in srs_requirements.items():
            status = "âœ…" if req_data['met'] else "âŒ"
            if req_name in ['accuracy_85_percent', 'phishing_recall_90_percent']:
                print(f"   {status} {req_name}: {req_data['current']:.1%} (target: {req_data['target']:.0%})")
            else:
                print(f"   {status} {req_name}: {req_data['current']:.0f} (target: {req_data['target']})")
        
        return compliance_results
    
    def _create_performance_test_set(self):
        """Create comprehensive performance test set."""
        
        # Diverse test cases for performance testing
        base_cases = [
            ('sbi.co.in', 'sbi-secure.tk'),
            ('icicibank.com', 'icici-banking.ml'),
            ('airtel.in', 'airtellor.xyz'),
            ('irctc.co.in', 'irctc-booking.ga'),
            ('hdfcbank.com', 'hdfc-netbanking.cf'),
            ('jio.com', 'reliancejio.top'),
            ('gov.in', 'india-gov.tk'),
            ('nic.in', 'nic-gov.ml'),
            ('bsnl.co.in', 'bsnl-portal.ga'),
            ('uidai.gov.in', 'aadhaar-update.cf')
        ]
        
        # Replicate for performance testing (200 total cases)
        test_cases = base_cases * 20
        
        return test_cases
    
    def _generate_final_report(self, perf_results, accuracy_results, compliance_results):
        """Generate comprehensive final optimization report."""
        
        print("ğŸ“„ Generating Final Optimization Report...")
        
        final_report = {
            'timestamp': datetime.now().isoformat(),
            'optimization_version': '2.0_comprehensive',
            'summary': {
                'performance_optimized': perf_results['meets_srs_throughput'],
                'accuracy_optimized': accuracy_results['meets_srs_accuracy'],
                'srs_compliant': compliance_results['fully_compliant'],
                'overall_status': self._determine_overall_status(compliance_results)
            },
            'performance_results': perf_results,
            'accuracy_results': {
                'metrics': accuracy_results['metrics'],
                'srs_compliance': {
                    'accuracy_met': accuracy_results['meets_srs_accuracy'],
                    'recall_met': accuracy_results['meets_srs_recall']
                }
            },
            'srs_compliance': compliance_results,
            'optimizations_applied': [
                'Ensemble weight rebalancing',
                'Feature extraction caching',
                'Batch processing optimization',
                'Dynamic threshold adjustment',
                'Advanced rule engine',
                'Vectorized operations'
            ],
            'key_improvements': {
                'throughput_increase': f"{perf_results['batch_throughput_per_minute']:.0f} domains/min vs 652 baseline",
                'response_time': f"{perf_results['single_prediction_avg_ms']:.1f}ms avg",
                'accuracy': f"{accuracy_results['metrics']['accuracy']:.1%} vs 82.6% baseline",
                'recall': f"{accuracy_results['metrics']['recall']:.1%} threat detection"
            }
        }
        
        # Save report
        report_file = f"FINAL_OPTIMIZATION_REPORT_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(final_report, f, indent=2, default=str)
        
        print(f"ğŸ’¾ Final report saved: {report_file}")
        
        # Print executive summary
        self._print_executive_summary(final_report)
        
        return final_report
    
    def _determine_overall_status(self, compliance_results):
        """Determine overall optimization status."""
        
        compliance_pct = compliance_results['compliance_percentage']
        
        if compliance_pct >= 100:
            return "FULLY_OPTIMIZED"
        elif compliance_pct >= 75:
            return "WELL_OPTIMIZED"
        elif compliance_pct >= 50:
            return "PARTIALLY_OPTIMIZED"
        else:
            return "NEEDS_FURTHER_OPTIMIZATION"
    
    def _print_executive_summary(self, report):
        """Print executive summary of optimizations."""
        
        print(f"\nğŸ† EXECUTIVE SUMMARY")
        print("=" * 30)
        
        summary = report['summary']
        improvements = report['key_improvements']
        
        status_icon = {
            'FULLY_OPTIMIZED': 'ğŸ¯',
            'WELL_OPTIMIZED': 'âœ…',
            'PARTIALLY_OPTIMIZED': 'âš ï¸',
            'NEEDS_FURTHER_OPTIMIZATION': 'âŒ'
        }.get(summary['overall_status'], 'â“')
        
        print(f"{status_icon} Overall Status: {summary['overall_status'].replace('_', ' ')}")
        
        print(f"\nğŸ“Š Key Improvements:")
        print(f"   ğŸš€ Throughput: {improvements['throughput_increase']}")
        print(f"   â±ï¸  Response: {improvements['response_time']}")
        print(f"   ğŸ¯ Accuracy: {improvements['accuracy']}")
        print(f"   ğŸ” Detection: {improvements['recall']}")
        
        print(f"\nâœ… SRS Compliance:")
        compliance = report['srs_compliance']
        print(f"   ğŸ“‹ Requirements met: {compliance['met_requirements']}/{compliance['total_requirements']}")
        print(f"   ğŸ“Š Compliance score: {compliance['compliance_percentage']:.1f}%")
        
        if summary['srs_compliant']:
            print(f"\nğŸ‰ CONGRATULATIONS: PhishGuard AI is now fully SRS compliant!")
        else:
            print(f"\nâš ï¸  Note: System is significantly improved but may need minor adjustments for full compliance")

if __name__ == "__main__":
    validator = OptimizationValidator()
    report = validator.run_comprehensive_validation()
    
    print(f"\nğŸ¯ OPTIMIZATION VALIDATION COMPLETE!")
    print(f"ğŸ“„ Detailed results saved for review")